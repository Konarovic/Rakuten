{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 21:25:36.873074: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-11 21:25:36.914624: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-11 21:25:36.914658: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-11 21:25:36.915888: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 21:25:36.923726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 21:25:37.674620: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n",
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/paramiko/transport.py:219: CryptographyDeprecationWarning:\n",
      "\n",
      "Blowfish has been deprecated\n",
      "\n",
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:\n",
      "\n",
      "\n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#Import config file. Update config.py according to your environment\n",
    "import config\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from Rakuten_preprocessing import Rakuten_img_path\n",
    "\n",
    "from src.text.classifiers import TFbertClassifier\n",
    "from src.image.classifiers import ImgClassifier\n",
    "from src.multimodal.classifiers import TFmultiClassifier\n",
    "\n",
    "from src.utils.batch import fit_save_all\n",
    "from src.utils.plot import plot_training_history\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(os.path.join(config.path_to_data, 'df_train_index.csv'))\n",
    "data_train['testset'] = False\n",
    "data_test = pd.read_csv(os.path.join(config.path_to_data, 'df_test_index.csv'))\n",
    "data_test['testset'] = True\n",
    "data = pd.concat([data_train, data_test], axis=0)\n",
    "\n",
    "#merging text into token column\n",
    "colnames = ['designation_translated', 'description_translated'] #['designation', 'description']#\n",
    "data['tokens'] = data[colnames].apply(lambda row: ' '.join(s.lower() for s in row if isinstance(s, str)), axis=1)\n",
    "\n",
    "#path to images into img_path column\n",
    "data['img_path'] = Rakuten_img_path(img_folder=config.path_to_images,\n",
    "                             imageid=data['imageid'], productid=data['productid'], suffix='_resized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels of encoded classes\n",
    "class_labels = data.groupby('prdtypedesignation')['prdtypeindex'].first().reset_index()\n",
    "class_labels.index = class_labels['prdtypeindex']\n",
    "class_labels = class_labels.drop(columns='prdtypeindex').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Img_train = data.loc[~data['testset'], 'img_path']\n",
    "Img_test = data.loc[data['testset'], 'img_path']\n",
    "\n",
    "Txt_train = data.loc[~data['testset'], 'tokens']\n",
    "Txt_test = data.loc[data['testset'], 'tokens']\n",
    "\n",
    "y_train = data.loc[~data['testset'],'prdtypeindex']\n",
    "y_test = data.loc[data['testset'],'prdtypeindex']\n",
    "\n",
    "#To be fed into any of our sklearn classifiers, X_train and X_test\n",
    "#should be dataframes with columns tokens and img_path\n",
    "X_train = pd.DataFrame({'tokens': Txt_train, 'img_path': Img_train})\n",
    "X_test = pd.DataFrame({'tokens': Txt_test, 'img_path': Img_test})\n",
    "\n",
    "#All data for cross-validated scores\n",
    "X = pd.concat([X_train, X_test], axis=0)\n",
    "y = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "#Number of classes\n",
    "num_classes = len(np.unique(data['prdtypeindex']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  vit_b16 None\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 21:26:13.818903: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:13.819272: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:13.876683: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:13.876774: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:13.876825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:13.876873: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:14.702348: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:14.702445: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:14.702499: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:14.702549: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:14.702594: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:14.702640: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:17.620188: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:17.620763: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:17.620879: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:17.620896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-11 21:26:17.620984: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:17.620996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 1, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-11 21:26:17.621131: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:17.621180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21558 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2024-03-11 21:26:17.622068: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 21:26:17.622117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21558 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:73:00.0, compute capability: 8.6\n",
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/vit_keras/utils.py:81: UserWarning:\n",
      "\n",
      "Resizing position embeddings from 24, 24 to 14, 14\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 21:26:26.235946: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 200 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Collective all_reduce tensors: 200 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 21:27:17.015432: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-03-11 21:27:17.044194: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-03-11 21:27:19.208636: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-11 21:27:23.342692: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fec5a31b4b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-11 21:27:23.342799: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2024-03-11 21:27:23.342818: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2024-03-11 21:27:23.360751: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710188843.579763 3966042 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 6.7729 - accuracy: 0.1050INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "32/32 [==============================] - 94s 651ms/step - loss: 6.7729 - accuracy: 0.1050 - lr: 5.0000e-05\n",
      "Found 1000 validated image filenames.\n",
      "32/32 [==============================] - 12s 199ms/step\n",
      "Test set, f1score:  0.14534219738551551\n",
      "Fitting:  ResNet50 None\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Found 1000 validated image filenames.\n",
      "INFO:tensorflow:Collective all_reduce tensors: 216 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 216 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 21:29:13.487347: E tensorflow/core/common_runtime/base_collective_executor.cc:249] BaseCollectiveExecutor::StartAbort INVALID_ARGUMENT: Shape mismatch in the collective instance 100. Op at device /job:localhost/replica:0/task:0/device:GPU:0 expected shape [23800347] but another member in the group expected shape [85899035]. This is likely due to different input shapes at different members of the collective op.\n",
      "2024-03-11 21:29:13.688917: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 379584842270698322\n",
      "2024-03-11 21:29:13.689084: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 9741236801729813815\n",
      "2024-03-11 21:29:13.689120: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13720746637280241199\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node CollectiveReduceV2_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_3965735/4292304250.py\", line 55, in <module>\n\n  File \"/mnt/c/Users/Julien Fournier/Documents/GitHub/RakutenTeam/src/utils/batch.py\", line 157, in fit_save_all\n\n  File \"/mnt/c/Users/Julien Fournier/Documents/GitHub/RakutenTeam/src/image/classifiers.py\", line 334, in fit\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/keras/src/optimizers/utils.py\", line 175, in _all_reduce_sum_fn\n\nCollective ops is aborted by: Shape mismatch in the collective instance 100. Op at device /job:localhost/replica:0/task:0/device:GPU:0 expected shape [23800347] but another member in the group expected shape [85899035]. This is likely due to different input shapes at different members of the collective op.\nThe error could be from a previous operation. Restart your program to reset.\n\t [[{{node CollectiveReduceV2_1}}]] [Op:__inference_train_function_170946]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 55\u001b[0m\n\u001b[1;32m     44\u001b[0m   params_list\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodality\u001b[39m\u001b[38;5;124m'\u001b[39m: modality,\n\u001b[1;32m     45\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: class_type,\n\u001b[1;32m     46\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_name\u001b[39m\u001b[38;5;124m'\u001b[39m: base_name, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfolds_grid\u001b[39m\u001b[38;5;124m'\u001b[39m: nfolds_grid, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfolds_cv\u001b[39m\u001b[38;5;124m'\u001b[39m: nfolds_cv\n\u001b[1;32m     52\u001b[0m                     })\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#Running the batch over params_list\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m results \u001b[38;5;241m=\u001b[39m fit_save_all(params_list, X_train\u001b[38;5;241m=\u001b[39mX_train[:\u001b[38;5;241m1000\u001b[39m], y_train\u001b[38;5;241m=\u001b[39my_train[:\u001b[38;5;241m1000\u001b[39m], X_test\u001b[38;5;241m=\u001b[39mX_test[:\u001b[38;5;241m1000\u001b[39m], y_test\u001b[38;5;241m=\u001b[39my_test[:\u001b[38;5;241m1000\u001b[39m], result_file_name \u001b[38;5;241m=\u001b[39m result_file_name)\n",
      "File \u001b[0;32m/mnt/c/Users/Julien Fournier/Documents/GitHub/RakutenTeam/src/utils/batch.py:157\u001b[0m, in \u001b[0;36mfit_save_all\u001b[0;34m(params_list, X_train, y_train, X_test, y_test, result_file_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m     clf \u001b[38;5;241m=\u001b[39m gridcv\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m    158\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_params\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m#Calculating scores on test set\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/Julien Fournier/Documents/GitHub/RakutenTeam/src/image/classifiers.py:334\u001b[0m, in \u001b[0;36mImgClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    331\u001b[0m             fit_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_data\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset_val\n\u001b[1;32m    333\u001b[0m         start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(dataset, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;66;03m#if self.epochs = 0, we just pass the model, considering it has already been trained\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rakuten/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/Rakuten/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node CollectiveReduceV2_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_3965735/4292304250.py\", line 55, in <module>\n\n  File \"/mnt/c/Users/Julien Fournier/Documents/GitHub/RakutenTeam/src/utils/batch.py\", line 157, in fit_save_all\n\n  File \"/mnt/c/Users/Julien Fournier/Documents/GitHub/RakutenTeam/src/image/classifiers.py\", line 334, in fit\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/keras/src/optimizers/utils.py\", line 175, in _all_reduce_sum_fn\n\nCollective ops is aborted by: Shape mismatch in the collective instance 100. Op at device /job:localhost/replica:0/task:0/device:GPU:0 expected shape [23800347] but another member in the group expected shape [85899035]. This is likely due to different input shapes at different members of the collective op.\nThe error could be from a previous operation. Restart your program to reset.\n\t [[{{node CollectiveReduceV2_1}}]] [Op:__inference_train_function_170946]"
     ]
    }
   ],
   "source": [
    "#Name of the summary csv file to save results to\n",
    "result_file_name = 'results_benchmark_img.csv'\n",
    "\n",
    "#type of modality\n",
    "modality = 'image'\n",
    "\n",
    "#Type of classifier\n",
    "class_type = 'ImgClassifier'\n",
    "\n",
    "#training parameters (or list of parameters for gridsearchCV)\n",
    "num_class = 27\n",
    "img_size = (224, 224, 3)\n",
    "n_epochs = 1#8\n",
    "batch_size = 32\n",
    "drop_rate = 0.2\n",
    "lr0 = 5e-5\n",
    "lr_min = 1e-6\n",
    "lr_decay_rate = 0.8\n",
    "\n",
    "#defining callbacks\n",
    "callbacks = []\n",
    "#adding earlystopping callback\n",
    "callbacks.append(('EarlyStopping', {'monitor': 'val_accuracy', 'min_delta': 0, 'mode': 'max', 'patience': 2, 'restore_best_weights': True, 'verbose': 1}))\n",
    "#Adding tensorboard callback as the last one\n",
    "callbacks.append(('TensorBoard', {'log_dir': np.nan, 'histogram_freq': 1, 'update_freq': 'epoch'}))\n",
    "\n",
    "#grid search number of folds\n",
    "nfolds_grid = 0\n",
    "\n",
    "#cross-validation of f1-score\n",
    "nfolds_cv = 0\n",
    "\n",
    "#network to test\n",
    "base_name_list = ['vit_b16', 'ResNet50', 'ResNet101', 'EfficientNetB1', 'vit_b16', 'ResNet152']\n",
    "\n",
    "#Initializing the list of parameters to batch over\n",
    "params_list = []\n",
    "\n",
    "for base_name in base_name_list:\n",
    "  #Adjusting tensorboard log directory\n",
    "  log_dir = os.path.join(config.path_to_tflogs, 'VGG16', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  callbacks[-1][1]['log_dir'] = log_dir\n",
    "  #adding the set of parameters to the list\n",
    "  params_list.append({'modality': modality,\n",
    "                      'class': class_type,\n",
    "                      'base_name': base_name, \n",
    "                      'param_grid': {'img_size': img_size, 'num_class': num_class, 'drop_rate': drop_rate, \n",
    "                                    'epochs': n_epochs, 'batch_size': batch_size, \n",
    "                                    'learning_rate':lr0, 'lr_decay_rate': lr_decay_rate, 'lr_min': lr_min,\n",
    "                                    'validation_data': (X_test[:1000], y_test[:1000]), 'callbacks': [callbacks], 'parallel_gpu': False},\n",
    "                      'nfolds_grid': nfolds_grid, 'nfolds_cv': nfolds_cv\n",
    "                    })\n",
    "\n",
    "#Running the batch over params_list\n",
    "results = fit_save_all(params_list, X_train=X_train[:1000], y_train=y_train[:1000], X_test=X_test[:1000], y_test=y_test[:1000], result_file_name = result_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch and check the saved result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modality</th>\n",
       "      <th>class</th>\n",
       "      <th>vectorization</th>\n",
       "      <th>classifier</th>\n",
       "      <th>tested_params</th>\n",
       "      <th>best_params</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_cv_test</th>\n",
       "      <th>score_cv_train</th>\n",
       "      <th>fit_cv_time</th>\n",
       "      <th>model_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image</td>\n",
       "      <td>ImgClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VGG16</td>\n",
       "      <td>{'img_size': [(224, 224, 3)], 'num_class': [27...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.443956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>image/VGG16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modality          class  vectorization classifier  \\\n",
       "0    image  ImgClassifier            NaN      VGG16   \n",
       "\n",
       "                                       tested_params  best_params  score_test  \\\n",
       "0  {'img_size': [(224, 224, 3)], 'num_class': [27...          NaN    0.443956   \n",
       "\n",
       "   score_cv_test  score_cv_train  fit_cv_time   model_path  \n",
       "0            NaN             NaN          NaN  image/VGG16  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(os.path.join(config.path_to_results, result_file_name), index_col=0)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize tensorflow logs in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3045096), started 0:00:04 ago. (Use '!kill 3045096' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-35f84bb2050e3078\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-35f84bb2050e3078\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_path = os.path.join(config.path_to_tflogs, 'VGG16')\n",
    "\n",
    "# Ensure the log_path is quoted to handle spaces\n",
    "quoted_log_path = f'\"{log_path}\"'\n",
    "\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir {quoted_log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 13:07:20.850430: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.850632: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.948389: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.948489: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.948545: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.948600: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.856774: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.856890: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.856948: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.857000: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.857048: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.857097: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.348939: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349407: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349486: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-10 13:07:24.349544: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 1, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-10 13:07:24.349628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21558 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2024-03-10 13:07:24.351034: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.351069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21558 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:73:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "#defining callbacks\n",
    "callbacks = []\n",
    "def lrscheduler(epoch, lr):\n",
    "  return max(1e-6, lr * 0.8)\n",
    "callbacks.append(('LearningRateScheduler', {'schedule': lrscheduler}))\n",
    "callbacks.append(('EarlyStopping', {'monitor': 'val_accuracy', 'min_delta': 0, 'mode': 'max', 'patience': 2, 'restore_best_weights': True, 'verbose': 1, }))\n",
    "\n",
    "clf = ImgClassifier(base_name='ResNet101', img_size=(224, 224, 3), num_class=27, drop_rate=0.2, epochs=5, batch_size=32, \n",
    "                    validation_data=(X_test, y_test), learning_rate=5e-5, callbacks=callbacks)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf.classification_score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rakuten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
