{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude de features pour la séparation ds différentes catégories de type \"Book\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les premières classifications effectuées, nous avons eu des difficulté à séparer certaines catégories, notamment les suivantes:\n",
    "| PrdTypeCode | Catégorie |\n",
    "|-------|-------|\n",
    "|10| Livres occasion|\n",
    "|2280| Magazines occasion|\n",
    "|2403| Livres BD magazines|\n",
    "|2705| Livres neufs|\n",
    "\n",
    "Ainsi, nous allos dans ce notebook chercher à identifier, à partir de designation et description, des features qui permettent de séparer ces classes, et tester une séparation de ces features pour ces catégories à partir d'algorithmes communs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Récupérer le fichier parent en tant que BASE_DIR\n",
    "BASE_DIR = \"C:/Users/mangg/projects/rakutenteam\"\n",
    "os.chdir(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/clean/X_train.csv\", index_col=0)\n",
    "target = pd.read_csv(\"data/clean/Y_train.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.text.transformers.extractors import YearExtractor, NumberExtractor\n",
    "from src.features.text.transformers.text_merger import TextMerger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2     True\n",
       "3     True\n",
       "4     True\n",
       "5     True\n",
       "6     True\n",
       "7     True\n",
       "8     True\n",
       "9     True\n",
       "10    True\n",
       "11    True\n",
       "12    True\n",
       "13    True\n",
       "14    True\n",
       "15    True\n",
       "16    True\n",
       "17    True\n",
       "18    True\n",
       "19    True\n",
       "Name: has_number, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_extractor = NumberExtractor(text_column=\"designation\")\n",
    "numbers = number_extractor.fit_transform(df)\n",
    "numbers.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_extractor = YearExtractor(text_column=\"designation\")\n",
    "years = year_extractor.fit_transform(df)\n",
    "years.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_codes = [10, 2280, 2403, 2705]\n",
    "book_filter = target.prdtypecode.isin(book_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_info = years.to_frame().join(target).loc[book_filter]\n",
    "book_info[\"has_year\"] = book_info.year.notnull()\n",
    "book_info[\"book_type\"] = book_info.prdtypecode.map({10: \"Livres occasion\", 2280: \"Magazines occasion\", 2403: \"Livres BD magazines\", 2705: \"Livres neufs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_info .info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=book_info, x=\"book_type\", hue=\"has_year\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Présence d'année dans la designation des produits de type Livres en fonction de la catégorie de livre\")\n",
    "plt.xlabel(\"Catégorie de livre\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Group the data by book type and extract the years\n",
    "\n",
    "# Plot the boxplot using seaborn\n",
    "sns.boxplot(data=book_info, x=\"book_type\", y=\"year\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Book Type\")\n",
    "plt.ylabel(\"Year\")\n",
    "plt.xticks(rotation=45, )\n",
    "plt.title(\"Boxplot of Years by Book Type\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=book_info, x=\"year\", hue=\"book_type\", kde=True, bins=40, palette=\"viridis\")\n",
    "plt.title(\"Distribution of Years by Book Type\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.xlim(1850, 2025)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.text.transformers.text_merger import TextMerger\n",
    "\n",
    "merger = TextMerger(designation_column=\"designation\", description_column=\"description\", merged_column=\"full_description\")\n",
    "merged_text = merger.fit_transform(df)\n",
    "df[\"full_description\"] = merged_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_description_years = df.full_description.str.extract(pattern, expand=False).rename(\"year\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_book_info = full_description_years.to_frame().join(target).loc[book_filter]\n",
    "full_book_info[\"has_year\"] = full_book_info.year.notnull()\n",
    "full_book_info[\"book_type\"] = full_book_info.prdtypecode.map({10: \"Livres occasion\", 2280: \"Magazines occasion\", 2403: \"Livres BD magazines\", 2705: \"Livres neufs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=full_book_info, x=\"book_type\", hue=\"has_year\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Présence d'année dans la description globale des produits de type Livres en fonction de la catégorie de livre\")\n",
    "plt.xlabel(\"Catégorie de livre\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=full_book_info, x=\"book_type\", y=\"year\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Book Type\")\n",
    "plt.ylabel(\"Year\")\n",
    "plt.xticks(rotation=45, )\n",
    "plt.title(\"Boxplot of Years by Book Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2     True\n",
       "3     True\n",
       "4     True\n",
       "5     True\n",
       "6     True\n",
       "7     True\n",
       "8     True\n",
       "9     True\n",
       "10    True\n",
       "11    True\n",
       "12    True\n",
       "13    True\n",
       "14    True\n",
       "15    True\n",
       "16    True\n",
       "17    True\n",
       "18    True\n",
       "19    True\n",
       "Name: has_number, dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.features.text.transformers.extractors import NumberExtractor\n",
    "\n",
    "number_extractor = NumberExtractor(text_column=\"designation\")\n",
    "numbers = number_extractor.fit_transform(df)\n",
    "numbers.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_number_pattern = r\"([Nn]\\s?°\\s?\\d+)\"\n",
    "\n",
    "mag_numbers = df.designation.str.extract(mag_number_pattern, expand=False).rename(\"mag_number\")\n",
    "\n",
    "mag_number_info = mag_numbers.to_frame().join(target).loc[book_filter]\n",
    "mag_number_info[\"has_mag_number\"] = mag_number_info.mag_number.notnull()\n",
    "mag_number_info[\"book_type\"] = mag_number_info.prdtypecode.map({10: \"Livres occasion\", 2280: \"Magazines occasion\", 2403: \"Livres BD magazines\", 2705: \"Livres neufs\"})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=mag_number_info, x=\"book_type\", hue=\"has_mag_number\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Présence de numéro de magazine dans la designation des produits de type Livres en fonction de la catégorie de livre\")\n",
    "plt.xlabel(\"Catégorie de livre\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_mag_numbers = df.full_description.str.extract(mag_number_pattern, expand=False).rename(\"mag_number\")\n",
    "\n",
    "full_mag_number_info = full_mag_numbers.to_frame().join(target).loc[book_filter]\n",
    "full_mag_number_info[\"has_mag_number\"] = full_mag_number_info.mag_number.notnull()\n",
    "full_mag_number_info[\"book_type\"] = full_mag_number_info.prdtypecode.map({10: \"Livres occasion\", 2280: \"Magazines occasion\", 2403: \"Livres BD magazines\", 2705: \"Livres neufs\"})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=full_mag_number_info, x=\"book_type\", hue=\"has_mag_number\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Présence de numéro de magazine dans la description globale des produits de type Livres en fonction de la catégorie de livre\")\n",
    "plt.xlabel(\"Catégorie de livre\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_number_pattern = r\"(#[\\d\\s\\-]+)\"\n",
    "hashtags = df.full_description.str.extract(hashtag_number_pattern, expand=False).rename(\"hashtag_number\")\n",
    "\n",
    "hashtag_info = hashtags.to_frame().join(target).loc[book_filter]\n",
    "hashtag_info[\"has_hashtag_number\"] = hashtag_info.hashtag_number.notnull()\n",
    "hashtag_info[\"book_type\"] = hashtag_info.prdtypecode.map({10: \"Livres occasion\", 2280: \"Magazines occasion\", 2403: \"Livres BD magazines\", 2705: \"Livres neufs\"})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=hashtag_info, x=\"book_type\", hue=\"has_hashtag_number\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Présence de hashtag dans la description globale des produits de type Livres en fonction de la catégorie de livre\")\n",
    "plt.xlabel(\"Catégorie de livre\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.full_description.loc[book_filter].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_book_info = full_book_info.join(full_mag_number_info.has_mag_number).join(hashtag_info.has_hashtag_number)\n",
    "complete_book_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude de corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula as smf\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude de la corrélation entre la présence d'année et le type de livre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(complete_book_info.has_year, complete_book_info.book_type, colnames=[\"Type de livre\"], rownames=[\"Présence d'année\"])\n",
    "contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.chi2_contingency(contingency)\n",
    "print(f\"On obtient le résultat {res.statistic:.2f}, avec la p-value {res.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude de la corrélation entre l'année détectée et le type de livre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = smf.api.ols(\"year ~ book_type\", data=complete_book_info).fit()\n",
    "table = sm.stats.anova_lm(res)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noous pouvons ici valider l'hypothèse d'une corrélation entre l'année détectée et le type de livre avec une p-value très inférieure à 5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude de la corrélation entre la présence de numéro de magazine et le type de livre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(complete_book_info.has_mag_number, complete_book_info.book_type, colnames=[\"Type de livre\"], rownames=[\"Présence de N°\"])\n",
    "contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.chi2_contingency(contingency)\n",
    "print(f\"On obtient le résultat {res.statistic:.2f}, avec la p-value {res.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude de la corrélation entre  présence de hashtag dans la description des produits et le type livre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(complete_book_info.has_hashtag_number, complete_book_info.book_type, colnames=[\"Type de livre\"], rownames=[\"Présence de N°\"])\n",
    "contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.chi2_contingency(contingency)\n",
    "print(f\"On obtient le résultat {res.statistic:.2f}, avec la p-value {res.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les features créées semblent toutes cohérentes pour identifier les catégories, ce que nous allons tenter de faire par la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données pour le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation de data et target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = complete_book_info.prdtypecode\n",
    "data = complete_book_info.drop(columns=[\"prdtypecode\", \"book_type\"]).fillna(0)\n",
    "data = data.astype(int)\n",
    "data.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "scaled_data = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "scaled_data.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_data, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining models to experiment with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = SVC(random_state=42)\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "clf_lr = LogisticRegression(random_state=42)\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_dum = DummyClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = {\"C\": [0.1, 1, 10, 100], \"gamma\": [1, 0.1, 0.01, 0.001], \"kernel\": [\"rbf\", \"poly\", \"sigmoid\"]}\n",
    "rf_params = {\"n_estimators\": [10, 100, 1000], \"max_depth\": [None, 5, 10, 20, 30], \"min_samples_split\": [2, 5, 10], \"min_samples_leaf\": [1, 2, 4]}\n",
    "lr_params = {\"C\": [0.1, 1, 10, 100], \"penalty\": [\"l1\", \"l2\"]}\n",
    "knn_params = {\"n_neighbors\": [3, 5, 11, 19], \"weights\": [\"uniform\", \"distance\"], \"metric\": [\"euclidean\", \"manhattan\"]}\n",
    "dum_params = {\"strategy\": [\"stratified\", \"most_frequent\", \"prior\", \"uniform\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    (\"Dummy\", clf_dum, dum_params),\n",
    "    (\"SVC\", clf_svc, svc_params),\n",
    "    (\"Random Forest\", clf_rf, rf_params),\n",
    "    (\"Logistic Regression\", clf_lr, lr_params),\n",
    "    (\"KNN\", clf_knn, knn_params),\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=[\"Accuracy\"], index=[\"Dummy\", \"SVC\", \"Random Forest\", \"Logistic Regression\", \"KNN\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf, params in classifiers:\n",
    "    print (f\"Training {name}...\")\n",
    "    grid = GridSearchCV(clf, params, cv=4, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"Meilleurs paramètres pour {name}: {grid.best_params_}\")\n",
    "    print(f\"Meilleur score pour {name}: {grid.best_score_:.3f}\")\n",
    "    test_score = grid.score(X_test, y_test)\n",
    "    print(f\"Score sur le test set pour {name}: {test_score:.3f}\")\n",
    "    results.loc[name, \"Accuracy\"] = test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rakuten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
