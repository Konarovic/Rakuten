{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorisation de type TF-IDF sur les données textuelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies et des data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T09:37:25.550652400Z",
     "start_time": "2024-02-14T09:37:24.095286400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mangg\\projects\\RakutenTeam c:\\Users\\mangg\\projects\\RakutenTeam\\data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "print(BASE_DIR, DATA_DIR)\n",
    "os.chdir(BASE_DIR)\n",
    "from src.features.text.transformers.text_merger import TextMerger\n",
    "from src.features.text.transformers.extractors import YearExtractor, NumberExtractor, HashtagNumberExtractor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T09:37:27.125644400Z",
     "start_time": "2024-02-14T09:37:25.552842400Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, \"clean/X_train.csv\"), index_col=0)\n",
    "target = pd.read_csv(os.path.join(DATA_DIR, \"clean/Y_train.csv\"), index_col=0)[\"prdtypecode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merger = TextMerger(designation_column=\"designation\", description_column=\"description\", merged_column=\"full_description\")\n",
    "merged_text = merger.fit_transform(df)\n",
    "df[\"full_description\"] = merged_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T09:37:35.011942Z",
     "start_time": "2024-02-14T09:37:28.854564900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "vectorized_text = pd.DataFrame(data=vectorizer.fit_transform(df.full_description).toarray(), columns=vectorizer.get_feature_names_out(), index=df.index)\n",
    "vectorized_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting 'N°' info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_extractor = NumberExtractor(text_column=\"full_description\")\n",
    "numbers = number_extractor.fit_transform(df)\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting year info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_extractor = YearExtractor(text_column=\"full_description\")\n",
    "years = year_extractor.fit_transform(df)\n",
    "years.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Hashtag number info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_extractor = HashtagNumberExtractor(text_column=\"full_description\")\n",
    "hashtags = hashtags_extractor.fit_transform(df)\n",
    "hashtags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging and Scaling extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = pd.concat([numbers, years, hashtags], axis=1)\n",
    "extracted_features.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_features = pd.DataFrame(data=scaler.fit_transform(extracted_features), columns=extracted_features.columns, index=extracted_features.index)\n",
    "scaled_features.describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([vectorized_text, scaled_features], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating Training Set and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T09:37:44.817881200Z",
     "start_time": "2024-02-14T09:37:43.899280900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining models to experiment with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = SVC(random_state=42)\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "clf_lr = LogisticRegression(random_state=42)\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_dum = DummyClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Défining Param Grids for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = {\"C\": [0.1, 1, 10, 100], \"gamma\": [1, 0.1, 0.01, 0.001], \"kernel\": [\"rbf\", \"poly\", \"sigmoid\"]}\n",
    "rf_params = {\"n_estimators\": [10, 100, 1000], \"max_depth\": [None, 5, 10, 20, 30], \"min_samples_split\": [2, 5, 10], \"min_samples_leaf\": [1, 2, 4]}\n",
    "lr_params = {\"C\": [0.1, 1, 10, 100], \"penalty\": [\"l1\", \"l2\"]}\n",
    "knn_params = {\"n_neighbors\": [3, 5, 11, 19], \"weights\": [\"uniform\", \"distance\"], \"metric\": [\"euclidean\", \"manhattan\"]}\n",
    "dum_params = {\"strategy\": [\"stratified\", \"most_frequent\", \"prior\", \"uniform\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting classifiers tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T15:27:58.389272500Z",
     "start_time": "2024-02-14T14:50:11.150268700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    (\"Dummy\", clf_dum, dum_params),\n",
    "    (\"SVC\", clf_svc, svc_params),\n",
    "    (\"Random Forest\", clf_rf, rf_params),\n",
    "    (\"Logistic Regression\", clf_lr, lr_params),\n",
    "    (\"KNN\", clf_knn, knn_params),\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting results tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=[\"Accuracy\", \"Best params\"], index=[\"Dummy\", \"SVC\", \"Random Forest\", \"Logistic Regression\", \"KNN\"])\n",
    "best_models = []\n",
    "best_params = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Grid Search CV for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, clf, params in classifiers:\n",
    "    print (f\"Training {name}...\")\n",
    "    grid = GridSearchCV(clf, params, cv=5, n_jobs=3, verbose=1, scoring=\"accuracy\")\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"Meilleurs paramètres pour {name}: {grid.best_params_}\")\n",
    "    print(f\"Meilleur score pour {name}: {grid.best_score_:.3f}\")\n",
    "    test_score = grid.score(X_test, y_test)\n",
    "    print(f\"Score sur le test set pour {name}: {test_score:.3f}\")\n",
    "    results.loc[name, \"Accuracy\"] = test_score\n",
    "    best_models.append({name: grid.best_estimator_})\n",
    "    best_params.append({name: grid.best_params_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Results of best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rakuten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
