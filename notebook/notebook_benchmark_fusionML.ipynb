{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.utils.saveload'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultimodal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifiers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFmultiClassifier, MetaClassifier\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_classifier\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fit_save_all\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_training_history\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "File \u001b[0;32m/mnt/c/Users/Julien Fournier/Documents/GitHub/RakutenTeam/src/utils/batch.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifiers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImgClassifier\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultimodal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifiers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetaClassifier, TFmultiClassifier\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaveload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_classifier\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, StratifiedKFold\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_save_all\u001b[39m(params_list, X_train, y_train, X_test, y_test, result_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.utils.saveload'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#Adding the source code to python path\n",
    "projectDir = '/mnt/c/Users/Julien Fournier/Documents/GitHub/RakutenTeam'\n",
    "sys.path.append(projectDir)\n",
    "\n",
    "#Import config file. Update config.py according to your environment\n",
    "import config\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Rakuten_preprocessing import Rakuten_img_path\n",
    "\n",
    "from src.text.classifiers import TFbertClassifier\n",
    "from src.image.classifiers import ImgClassifier\n",
    "from src.multimodal.classifiers import TFmultiClassifier, MetaClassifier\n",
    "\n",
    "from src.utils.load import load_classifier\n",
    "from src.utils.batch import fit_save_all\n",
    "from src.utils.plot import plot_training_history\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(os.path.join(config.path_to_data, 'df_train_index.csv'))\n",
    "data_train['testset'] = False\n",
    "data_test = pd.read_csv(os.path.join(config.path_to_data, 'df_test_index.csv'))\n",
    "data_test['testset'] = True\n",
    "data = pd.concat([data_train, data_test], axis=0)\n",
    "\n",
    "#merging text into token column\n",
    "colnames = ['designation_translated', 'description_translated'] #['designation', 'description']#\n",
    "data['tokens'] = data[colnames].apply(lambda row: ' '.join(s.lower() for s in row if isinstance(s, str)), axis=1)\n",
    "    \n",
    "#path to images into img_path column\n",
    "data['img_path'] = Rakuten_img_path(img_folder=config.path_to_images,\n",
    "                             imageid=data['imageid'], productid=data['productid'], suffix='_resized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels of encoded classes\n",
    "class_labels = data.groupby('prdtypedesignation')['prdtypeindex'].first().reset_index()\n",
    "class_labels.index = class_labels['prdtypeindex']\n",
    "class_labels = class_labels.drop(columns='prdtypeindex').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Img_train = data.loc[~data['testset'], 'img_path']\n",
    "Img_test = data.loc[data['testset'], 'img_path']\n",
    "\n",
    "Txt_train = data.loc[~data['testset'], 'tokens']\n",
    "Txt_test = data.loc[data['testset'], 'tokens']\n",
    "\n",
    "y_train = data.loc[~data['testset'],'prdtypeindex']\n",
    "y_test = data.loc[data['testset'],'prdtypeindex']\n",
    "\n",
    "#To be fed into any of our sklearn classifiers, X_train and X_test\n",
    "#should be dataframes with columns tokens and img_path\n",
    "X_train = pd.DataFrame({'tokens': Txt_train, 'img_path': Img_train})\n",
    "X_test = pd.DataFrame({'tokens': Txt_test, 'img_path': Img_test})\n",
    "\n",
    "#All data for cross-validated scores\n",
    "X = pd.concat([X_train, X_test], axis=0)\n",
    "y = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "#Number of classes\n",
    "num_classes = len(np.unique(data['prdtypeindex']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting and stacking models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from Local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertModel.\n",
      "\n",
      "All the layers of TFCamembertModel were initialized from the model checkpoint at /mnt/c/Users/Julien Fournier/Documents/DST/RakutenProject/models/base_models/camembert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertModel for predictions without further training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  bert-test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/vit_keras/utils.py:81: UserWarning:\n",
      "\n",
      "Resizing position embeddings from 24, 24 to 14, 14\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  vit-test\n"
     ]
    }
   ],
   "source": [
    "#Loading pre-trained model and specifying from_trained ansd epoch = 0 \n",
    "# so that the voting classifier doesn't refit them\n",
    "model_bert2 = load_classifier(name='bert-test')\n",
    "model_bert2.lr_min = 1e-6\n",
    "model_bert2.from_trained = 'bert-test'\n",
    "model_bert2.epochs = 0\n",
    "\n",
    "model_vit2 = load_classifier(name='vit-test')\n",
    "model_vit2.lr_min = 1e-6\n",
    "model_vit2.from_trained = 'vit-test'\n",
    "model_vit2.epoch = 0\n",
    "\n",
    "# vot_clf = MetaClassifier(base_estimators=[('bert', model_bert2), ('vit', model_vit2)], meta_method='voting', voting='soft', weights=[0.5, 0.5])\n",
    "\n",
    "\n",
    "logi_clf = LogisticRegression(C=1)\n",
    "vot_clf = MetaClassifier(base_estimators=[('bert', model_bert2), ('vit', model_vit2)], final_estimator=logi_clf ,meta_method='stacking', cv='prefit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  bert-test vit-test nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 17:33:27.729151: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:27.729551: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:27.794419: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:27.794512: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:27.794566: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:27.794619: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:28.386022: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:28.386137: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:28.386193: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:28.386244: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:28.386290: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:28.386336: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:30.638342: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:30.638815: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:30.638888: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:30.638899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-11 17:33:30.638949: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:30.638956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 1, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-11 17:33:30.639037: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:30.639065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21558 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2024-03-11 17:33:30.640054: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 17:33:30.640090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21558 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:73:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from Local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertModel.\n",
      "\n",
      "All the layers of TFCamembertModel were initialized from the model checkpoint at /mnt/c/Users/Julien Fournier/Documents/DST/RakutenProject/models/base_models/camembert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertModel for predictions without further training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  bert-test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/vit_keras/utils.py:81: UserWarning:\n",
      "\n",
      "Resizing position embeddings from 24, 24 to 14, 14\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  vit-test\n",
      "loading from Local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertModel.\n",
      "\n",
      "All the layers of TFCamembertModel were initialized from the model checkpoint at /mnt/c/Users/Julien Fournier/Documents/DST/RakutenProject/models/base_models/camembert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertModel for predictions without further training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  bert-test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/vit_keras/utils.py:81: UserWarning:\n",
      "\n",
      "Resizing position embeddings from 24, 24 to 14, 14\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  vit-test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 17:34:57.106677: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531/531 [==============================] - 158s 282ms/step\n",
      "Found 16984 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 17:37:35.785773: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-03-11 17:37:38.999012: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531/531 [==============================] - 137s 244ms/step\n",
      "Test set, f1score:  0.20417604933572872\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 57\u001b[0m\n\u001b[1;32m     48\u001b[0m     params_list\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodality\u001b[39m\u001b[38;5;124m'\u001b[39m: modality,\n\u001b[1;32m     49\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: class_type,\n\u001b[1;32m     50\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_name\u001b[39m\u001b[38;5;124m'\u001b[39m: base_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfolds_grid\u001b[39m\u001b[38;5;124m'\u001b[39m: nfolds_grid, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfolds_cv\u001b[39m\u001b[38;5;124m'\u001b[39m: nfolds_cv\n\u001b[1;32m     54\u001b[0m                       })\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#Running the batch over params_list\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m results \u001b[38;5;241m=\u001b[39m fit_save_all(params_list, X_train\u001b[38;5;241m=\u001b[39mX_train, y_train\u001b[38;5;241m=\u001b[39my_train, X_test\u001b[38;5;241m=\u001b[39mX_test, y_test\u001b[38;5;241m=\u001b[39my_test, result_file_name \u001b[38;5;241m=\u001b[39m result_file_name)\n",
      "File \u001b[0;32m/mnt/c/Users/Julien Fournier/Documents/GitHub/RakutenTeam/src/utils/batch.py:184\u001b[0m, in \u001b[0;36mfit_save_all\u001b[0;34m(params_list, X_train, y_train, X_test, y_test, result_file_name)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvec_method\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m    183\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodality\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvec_method\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta_method\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m    185\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodality\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "#Name of the summary csv file to save results to\n",
    "result_file_name = 'results_benchmark_fusion_meta.csv'\n",
    "\n",
    "#type of modality\n",
    "modality = 'fusion'\n",
    "\n",
    "#Type of classifier\n",
    "class_type = 'MetaClassifier'\n",
    "\n",
    "#training parameters (or list of parameters for gridsearchCV)\n",
    "num_class = 27\n",
    "max_length = 256\n",
    "n_epochs = 8\n",
    "batch_size = 32\n",
    "drop_rate = 0.2\n",
    "lr0 = 5e-5\n",
    "lr_min=1e-6\n",
    "lr_decay_rate = 0.8\n",
    "\n",
    "#grid search number of folds\n",
    "nfolds_grid = 0\n",
    "\n",
    "#cross-validation of f1-score\n",
    "nfolds_cv = 0\n",
    "\n",
    "#name of previously saved models to use as base estimators\n",
    "base_name_list = ['bert-test vit-test']\n",
    "\n",
    "voting_type = 'soft'\n",
    "voting_weights = [[0.5, 0.5]]\n",
    "\n",
    "stacking_estimator = LogisticRegression(C=1)\n",
    "stacking_cv = 'prefit'\n",
    "\n",
    "#Initializing the list of parameters to batch over\n",
    "params_list = []\n",
    "\n",
    "for base_name in base_name_list:\n",
    "    #adding the set of parameters to the list\n",
    "    params_list.append({'modality': modality,\n",
    "                        'class': class_type,\n",
    "                        'base_name': base_name,\n",
    "                        'meta_method': 'voting',\n",
    "                        'param_grid': {'voting': voting_type, 'weights': voting_weights},\n",
    "                        'nfolds_grid': nfolds_grid, 'nfolds_cv': nfolds_cv\n",
    "                      })\n",
    "        \n",
    "    params_list.append({'modality': modality,\n",
    "                        'class': class_type,\n",
    "                        'base_name': base_name,\n",
    "                        'meta_method': 'stacking',\n",
    "                        'param_grid': {'final_estimator': stacking_estimator, 'cv': stacking_cv},\n",
    "                        'nfolds_grid': nfolds_grid, 'nfolds_cv': nfolds_cv\n",
    "                      })\n",
    "  \n",
    "#Running the batch over params_list\n",
    "results = fit_save_all(params_list, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, result_file_name = result_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "np.isnan('tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize tensorflow logs in tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize tensorflow logs in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3002456), started 0:00:05 ago. (Use '!kill 3002456' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e4296bc399dcf964\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e4296bc399dcf964\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_path = os.path.join(config.path_to_tflogs, 'camembert-base')\n",
    "\n",
    "# Ensure the log_path is quoted to handle spaces\n",
    "quoted_log_path = f'\"{log_path}\"'\n",
    "\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir {quoted_log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 13:07:20.850430: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.850632: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.948389: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.948489: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.948545: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.948600: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.856774: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.856890: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.856948: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.857000: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.857048: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.857097: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.348939: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349407: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349486: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-10 13:07:24.349544: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 1, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-10 13:07:24.349628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21558 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2024-03-10 13:07:24.351034: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.351069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21558 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:73:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "#defining callbacks\n",
    "callbacks = []\n",
    "def lrscheduler(epoch, lr):\n",
    "  return max(1e-6, lr * 0.8)\n",
    "callbacks = callbacks.append(('LearningRateScheduler', {'schedule': lrscheduler}))\n",
    "callbacks = callbacks.append(('EarlyStopping', {'monitor': 'val_accuracy', 'min_delta': 0, 'mode': 'max', 'patience': 2, 'restore_best_weights': True, 'verbose': 1, }))\n",
    "\n",
    "clf = ImgClassifier(base_name='ResNet101', img_size=(224, 224, 3), num_class=27, drop_rate=0.2, epochs=5, batch_size=32, \n",
    "                    validation_data=(X_test, y_test), learning_rate=5e-5, callbacks=callbacks)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf.classification_score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rakuten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
