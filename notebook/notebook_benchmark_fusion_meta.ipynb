{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 18:02:33.672371: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-12 18:02:33.734759: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-12 18:02:33.734803: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-12 18:02:33.739479: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-12 18:02:33.756333: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-12 18:02:34.567582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n",
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/paramiko/transport.py:219: CryptographyDeprecationWarning:\n",
      "\n",
      "Blowfish has been deprecated\n",
      "\n",
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:\n",
      "\n",
      "\n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#Import config file. Update config.py according to your environment\n",
    "import config\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import datetime\n",
    "\n",
    "from Rakuten_preprocessing import Rakuten_img_path\n",
    "\n",
    "from src.text.classifiers import TFbertClassifier\n",
    "from src.image.classifiers import ImgClassifier\n",
    "from src.multimodal.classifiers import TFmultiClassifier, MetaClassifier\n",
    "\n",
    "from src.utils.load import load_classifier\n",
    "from src.utils.batch import fit_save_all\n",
    "from src.utils.plot import plot_training_history\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(os.path.join(config.path_to_data, 'df_train_index.csv'))\n",
    "data_train['testset'] = False\n",
    "data_test = pd.read_csv(os.path.join(config.path_to_data, 'df_test_index.csv'))\n",
    "data_test['testset'] = True\n",
    "data = pd.concat([data_train, data_test], axis=0)\n",
    "\n",
    "#merging text into token column\n",
    "colnames = ['designation_translated', 'description_translated'] #['designation', 'description']#\n",
    "data['tokens'] = data[colnames].apply(lambda row: ' '.join(s.lower() for s in row if isinstance(s, str)), axis=1)\n",
    "    \n",
    "#path to images into img_path column\n",
    "data['img_path'] = Rakuten_img_path(img_folder=config.path_to_images,\n",
    "                             imageid=data['imageid'], productid=data['productid'], suffix='_resized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels of encoded classes\n",
    "class_labels = data.groupby('prdtypedesignation')['prdtypeindex'].first().reset_index()\n",
    "class_labels.index = class_labels['prdtypeindex']\n",
    "class_labels = class_labels.drop(columns='prdtypeindex').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Img_train = data.loc[~data['testset'], 'img_path']\n",
    "Img_test = data.loc[data['testset'], 'img_path']\n",
    "\n",
    "Txt_train = data.loc[~data['testset'], 'tokens']\n",
    "Txt_test = data.loc[data['testset'], 'tokens']\n",
    "\n",
    "y_train = data.loc[~data['testset'],'prdtypeindex']\n",
    "y_test = data.loc[data['testset'],'prdtypeindex']\n",
    "\n",
    "#To be fed into any of our sklearn classifiers, X_train and X_test\n",
    "#should be dataframes with columns tokens and img_path\n",
    "X_train = pd.DataFrame({'tokens': Txt_train, 'img_path': Img_train})\n",
    "X_test = pd.DataFrame({'tokens': Txt_test, 'img_path': Img_test})\n",
    "\n",
    "#All data for cross-validated scores\n",
    "X = pd.concat([X_train, X_test], axis=0)\n",
    "y = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "#Number of classes\n",
    "num_classes = len(np.unique(data['prdtypeindex']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting and stacking models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from Local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertModel.\n",
      "\n",
      "All the layers of TFCamembertModel were initialized from the model checkpoint at /mnt/c/Users/Julien Fournier/Documents/DST/RakutenProject/models/base_models/camembert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertModel for predictions without further training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  bert-test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/vit_keras/utils.py:81: UserWarning:\n",
      "\n",
      "Resizing position embeddings from 24, 24 to 14, 14\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  vit-test\n"
     ]
    }
   ],
   "source": [
    "#Loading pre-trained model and specifying from_trained ansd epoch = 0 \n",
    "# so that the voting classifier doesn't refit them\n",
    "model_bert2 = load_classifier(name='bert-test')\n",
    "model_bert2.lr_min = 1e-6\n",
    "model_bert2.from_trained = 'bert-test'\n",
    "model_bert2.epochs = 0\n",
    "\n",
    "model_vit2 = load_classifier(name='vit-test')\n",
    "model_vit2.lr_min = 1e-6\n",
    "model_vit2.from_trained = 'vit-test'\n",
    "model_vit2.epoch = 0\n",
    "\n",
    "# vot_clf = MetaClassifier(base_estimators=[('bert', model_bert2), ('vit', model_vit2)], meta_method='voting', voting='soft', weights=[0.5, 0.5])\n",
    "\n",
    "\n",
    "logi_clf = LogisticRegression(C=1)\n",
    "vot_clf = MetaClassifier(base_estimators=[('bert', model_bert2), ('vit', model_vit2)], final_estimator=logi_clf ,meta_method='stacking', cv='prefit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4, 0.6], [0.6, 0.6], [0.5, 0.5], [0.5, 0.5]]\n",
      "Fitting:  text/camembert-base image/vit_b16 None\n",
      "loading from Local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertModel.\n",
      "\n",
      "All the layers of TFCamembertModel were initialized from the model checkpoint at /mnt/c/Users/Julien Fournier/Documents/DST/RakutenProject/models/base_models/camembert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertModel for predictions without further training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  text/camembert-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/vit_keras/utils.py:81: UserWarning:\n",
      "\n",
      "Resizing position embeddings from 24, 24 to 14, 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Name of the summary csv file to save results to\n",
    "result_file_name = 'results_benchmark_fusion_meta.csv'\n",
    "\n",
    "#type of modality\n",
    "modality = 'fusion'\n",
    "\n",
    "#Type of classifier\n",
    "class_type = 'MetaClassifier'\n",
    "\n",
    "#training parameters (or list of parameters for gridsearchCV)\n",
    "num_class = 27\n",
    "max_length = 256\n",
    "n_epochs = 8\n",
    "batch_size = 32\n",
    "drop_rate = 0.2\n",
    "lr0 = 5e-5\n",
    "lr_min=1e-6\n",
    "lr_decay_rate = 0.8\n",
    "\n",
    "#grid search number of folds\n",
    "nfolds_grid = 0\n",
    "\n",
    "#cross-validation of f1-score\n",
    "nfolds_cv = 0\n",
    "\n",
    "#name of previously saved models to use as base estimators\n",
    "base_name_list = ['text/camembert-base image/vit_b16']\n",
    "\n",
    "voting_type = 'soft'\n",
    "voting_weights = []\n",
    "for k in range(4, 6, 1):\n",
    "  voting_weights.append([k / 10, (10 - k) / 10])\n",
    "  voting_weights.append([(10 - k) / 10, k / 10])\n",
    "\n",
    "print(voting_weights)\n",
    "\n",
    "stacking_estimator = LogisticRegression(C=1)\n",
    "stacking_cv = 'prefit'\n",
    "\n",
    "#Initializing the list of parameters to batch over\n",
    "params_list = []\n",
    "\n",
    "for base_name in base_name_list:\n",
    "    #adding the set of parameters to the list\n",
    "    # params_list.append({'modality': modality,\n",
    "    #                     'class': class_type,\n",
    "    #                     'base_name': base_name,\n",
    "    #                     'meta_method': 'voting',\n",
    "    #                     'param_grid': {'voting': voting_type, 'weights': voting_weights},\n",
    "    #                     'nfolds_grid': 5, 'nfolds_cv': nfolds_cv\n",
    "    #                   })\n",
    "        \n",
    "    params_list.append({'modality': modality,\n",
    "                        'class': class_type,\n",
    "                        'base_name': base_name,\n",
    "                        'meta_method': 'stacking',\n",
    "                        'param_grid': {'final_estimator': stacking_estimator, 'cv': stacking_cv},\n",
    "                        'nfolds_grid': nfolds_grid, 'nfolds_cv': nfolds_cv\n",
    "                      })\n",
    "  \n",
    "#Running the batch over params_list\n",
    "results = fit_save_all(params_list, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, result_file_name = result_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from Local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertModel.\n",
      "\n",
      "All the layers of TFCamembertModel were initialized from the model checkpoint at /mnt/c/Users/Julien Fournier/Documents/DST/RakutenProject/models/base_models/camembert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertModel for predictions without further training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  fusion/text-camembert-base image-vit_b16_text/text/camembert-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jul/anaconda3/envs/Rakuten/lib/python3.11/site-packages/vit_keras/utils.py:81: UserWarning:\n",
      "\n",
      "Resizing position embeddings from 24, 24 to 14, 14\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  fusion/text-camembert-base image-vit_b16_text/image/vit_b16\n",
      "531/531 [==============================] - 149s 274ms/step\n",
      "Found 16984 validated image filenames.\n",
      "531/531 [==============================] - 138s 252ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.891793726604458"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = load_classifier('fusion/text-camembert-base image-vit_b16_text')\n",
    "clf.classification_score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize tensorflow logs in tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize tensorflow logs in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3002456), started 0:00:05 ago. (Use '!kill 3002456' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e4296bc399dcf964\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e4296bc399dcf964\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_path = os.path.join(config.path_to_tflogs, 'camembert-base')\n",
    "\n",
    "# Ensure the log_path is quoted to handle spaces\n",
    "quoted_log_path = f'\"{log_path}\"'\n",
    "\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir {quoted_log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 13:07:20.850430: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.850632: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.948389: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.948489: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.948545: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:20.948600: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.856774: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.856890: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.856948: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.857000: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.857048: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:21.857097: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.348939: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349407: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349486: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-10 13:07:24.349544: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 1, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-10 13:07:24.349628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:17:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.349681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21558 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2024-03-10 13:07:24.351034: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-10 13:07:24.351069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21558 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:73:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "#defining callbacks\n",
    "callbacks = []\n",
    "def lrscheduler(epoch, lr):\n",
    "  return max(1e-6, lr * 0.8)\n",
    "callbacks = callbacks.append(('LearningRateScheduler', {'schedule': lrscheduler}))\n",
    "callbacks = callbacks.append(('EarlyStopping', {'monitor': 'val_accuracy', 'min_delta': 0, 'mode': 'max', 'patience': 2, 'restore_best_weights': True, 'verbose': 1, }))\n",
    "\n",
    "clf = ImgClassifier(base_name='ResNet101', img_size=(224, 224, 3), num_class=27, drop_rate=0.2, epochs=5, batch_size=32, \n",
    "                    validation_data=(X_test, y_test), learning_rate=5e-5, callbacks=callbacks)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf.classification_score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rakuten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
